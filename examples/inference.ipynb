{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import dataclasses\n",
                "\n",
                "import jax\n",
                "import torch\n",
                "\n",
                "from openpi.models import model as _model\n",
                "from openpi.policies import droid_policy\n",
                "from openpi.policies import ur3_robotiq_policy\n",
                "from openpi.policies import policy_config as _policy_config\n",
                "from openpi.shared import download\n",
                "from openpi.training import config as _config\n",
                "from openpi.training import data_loader as _data_loader"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Policy inference\n",
                "\n",
                "The following example shows how to create a policy from a checkpoint and run inference on a dummy example."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Policy infer inputs: [0.84179922 0.90663587 0.75344159 0.66017157 0.41391253 0.97284278\n",
                        " 0.86954556] [0.00413281]\n",
                        "Policy infer transformed inputs: [ 0.95836034  0.55242179  0.96191687  1.96338149  0.30179398 -1.22520143\n",
                        "  0.35176651 -0.99165932]\n",
                        "Policy infer outputs: 4022.0\n",
                        "Policy infer transformed outputs: [ 0.17652283 -0.23692529 -0.30517823 -0.01090471 -0.17994839  0.24778192\n",
                        "  0.24548847 -0.00596324]\n",
                        "Actions shape: [ 0.17652283 -0.23692529 -0.30517823 -0.01090471 -0.17994839  0.24778192\n",
                        "  0.24548847 -0.00596324]\n"
                    ]
                }
            ],
            "source": [
                "config = _config.get_config(\"pi0_fast_droid\")\n",
                "checkpoint_dir = download.maybe_download(\"gs://openpi-assets/checkpoints/pi0_fast_droid\")\n",
                "\n",
                "# Create a trained policy.\n",
                "policy = _policy_config.create_trained_policy(config, checkpoint_dir)\n",
                "\n",
                "# Run inference on a dummy example. This example corresponds to observations produced by the DROID runtime.\n",
                "example = droid_policy.make_droid_example()\n",
                "result = policy.infer(example)\n",
                "\n",
                "# Delete the policy to free up memory.\n",
                "del policy\n",
                "\n",
                "print(\"Actions shape:\", result[\"actions\"][0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Working with a live model\n",
                "\n",
                "\n",
                "The following example shows how to create a live model from a checkpoint and compute training loss. First, we are going to demonstrate how to do it with fake data.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "config = _config.get_config(\"pi0_ur3_robotiq\")\n",
                "\n",
                "checkpoint_dir = download.maybe_download(\"gs://openpi-assets/checkpoints/pi0_base\")\n",
                "key = jax.random.key(0)\n",
                "\n",
                "# # Create a model from the checkpoint.\n",
                "# model = config.model.load(_model.restore_params(checkpoint_dir / \"params\"))\n",
                "\n",
                "# # We can create fake observations and actions to test the model.\n",
                "# obs, act = config.model.fake_obs(), config.model.fake_act()\n",
                "\n",
                "# # Sample actions from the model.\n",
                "# loss = model.compute_loss(key, obs, act)\n",
                "# print(\"Loss shape:\", loss.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, we are going to create a data loader and use a real batch of training data to compute the loss."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Reduce the batch size to reduce memory usage.\n",
                "config = dataclasses.replace(config, batch_size=2)\n",
                "\n",
                "# Load a single batch of data. This is the same data that will be used during training.\n",
                "# NOTE: In order to make this example self-contained, we are skipping the normalization step\n",
                "# since it requires the normalization statistics to be generated using `compute_norm_stats`.\n",
                "loader = _data_loader.create_data_loader(config, num_batches=1, skip_norm_stats=True)\n",
                "obs, act = next(iter(loader))\n",
                "\n",
                "# Sample actions from the model.\n",
                "loss = model.compute_loss(key, obs, act)\n",
                "\n",
                "# Delete the model to free up memory.\n",
                "del model\n",
                "\n",
                "print(\"Loss shape:\", loss.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Assets directory: /home/user/.cache/openpi/openpi-assets/checkpoints/pi0_base\n",
                        "[DIR] assets\n",
                        "  - aloha.lock\n",
                        "  - arx\n",
                        "  - arx_mobile\n",
                        "  - droid\n",
                        "  - fibocom_mobile\n",
                        "  - franka\n",
                        "  - trossen\n",
                        "  - trossen_mobile\n",
                        "  - ur5e\n",
                        "  - ur5e_dual\n",
                        "[DIR] params\n",
                        "  - _CHECKPOINT_METADATA\n",
                        "  - _METADATA\n",
                        "  - _sharding\n",
                        "  - d\n",
                        "  - manifest.ocdbt\n",
                        "  - ocdbt.process_0\n"
                    ]
                }
            ],
            "source": [
                "from pathlib import Path\n",
                "\n",
                "assets_root = download.maybe_download(\"gs://openpi-assets/checkpoints/pi0_base/\")\n",
                "print(f\"Assets directory: {assets_root}\")\n",
                "for entry in sorted(Path(assets_root).iterdir()):\n",
                "    if entry.is_dir():\n",
                "        print(f\"[DIR] {entry.name}\")\n",
                "        for child in sorted(entry.iterdir()):\n",
                "            print(f\"  - {child.name}\")\n",
                "    else:\n",
                "        print(f\"[FILE] {entry.name}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "309192273f6644c7900c5f5c3d1f5ec4",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0.00/4.40k [00:00<?, ?iB/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Assets directory: /home/user/.cache/openpi/openpi-assets/checkpoints/pi0_libero/assets\n",
                        "[DIR] physical-intelligence\n",
                        "  - libero\n"
                    ]
                }
            ],
            "source": [
                "from pathlib import Path\n",
                "\n",
                "assets_root = download.maybe_download(\"gs://openpi-assets/checkpoints/pi0_libero/assets/\")\n",
                "print(f\"Assets directory: {assets_root}\")\n",
                "for entry in sorted(Path(assets_root).iterdir()):\n",
                "    if entry.is_dir():\n",
                "        print(f\"[DIR] {entry.name}\")\n",
                "        for child in sorted(entry.iterdir()):\n",
                "            print(f\"  - {child.name}\")\n",
                "    else:\n",
                "        print(f\"[FILE] {entry.name}\")\n",
                "        print(f\"[FILE] {entry}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "start:  2025-12-07 17:05:27\n",
                        "Using PyTorch device: cuda\n",
                        "Policy created:  2025-12-07 17:06:05\n",
                        "Example state: [ 2.74 -1.65  0.49 -1.55 -0.45  0.18  0.5 ]\n",
                        "Example images: {'cam_high': (2048, 2048, 3), 'cam_left_wrist': (2048, 2048, 3)}\n",
                        "input before transform: [ 2.74 -1.65  0.49 -1.55 -0.45  0.18  0.5 ]\n",
                        "input before transform (degrees): [156.99043  -94.53803   28.074932 -88.80846  -25.7831    10.31324\n",
                        "  28.647888]\n",
                        "output after transform: [-0.03538096  0.1144994  -0.02814207  0.00599358 -0.09668985  0.09598636\n",
                        "  0.8825611 ]\n",
                        "output after transform (degrees): [-2.0271795   6.5603323  -1.612422    0.34340695 -5.5399203   5.499613\n",
                        " 50.567024  ]\n",
                        "Inference completed:  2025-12-07 17:06:18\n"
                    ]
                }
            ],
            "source": [
                "import time\n",
                "print(\"start: \", time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
                "config = _config.get_config(\"pi0_ur3_robotiq\")\n",
                "checkpoint_dir = download.maybe_download(\"gs://openpi-assets/checkpoints/pi0_base_pytorch\")\n",
                "torch.manual_seed(42)\n",
                "# Create a trained policy.\n",
                "policy = _policy_config.create_trained_policy(config, checkpoint_dir)\n",
                "print(\"Policy created: \", time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
                "\n",
                "# Run inference on a dummy example. This example corresponds to observations produced by the DROID runtime.\n",
                "example = ur3_robotiq_policy.make_ur3_example()\n",
                "print(\"Example state:\", example[\"state\"])\n",
                "print(\"Example images:\", {k: v.shape for k, v in example[\"images\"].items()})\n",
                "result = policy.infer(example)\n",
                "print(\"Inference completed: \", time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
                "\n",
                "# Delete the policy to free up memory.\n",
                "del policy"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
